{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fy_MOIQqmeHg"
   },
   "source": [
    " <center> Module EL 3019 \n",
    " \n",
    " <font color=\"#0066CC\"> **Méthode des K plus proches voisins (Régression)** </font> </center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9rOVd6UxpA8J"
   },
   "source": [
    "1. Objectifs  \n",
    "2. Chargement des bibliothèques et du jeu de données \n",
    "3. Prérequis\n",
    "4. KPPV en régression\n",
    "\n",
    "<hr>\n",
    "\n",
    "<font color=\"#0066CC\"> 1. Les objectifs  </font> \n",
    "- Ce TP a pour objectif d'apprendre à réaliser le méthode des k plus proches voisins en régression à l'aide de python et des packages appropriés\n",
    "- En introduction, nous utiliserons cette méthode sur le jeux de données complet puis nous réaliserons un échantillonage dans l'objectif de déterminer le k optimal.\n",
    "\n",
    "<u>*remarque importante*</u> : les statistiques univariées (disribution, histogrammes) et bivariées (correlations entre les variables, scatter plot) sont intentionnellement omises dans ce TP  (ce n'est pas son objectif). Il n'en demeure pas moins qu'elles doivent être **systématiquement** réalisées lors de l'étude d'un jeux de données \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9rOVd6UxpA8J"
   },
   "source": [
    "<font color=\"#0066CC\">2. Chargement des bibliothèques et du jeu de données </font>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "1CHquFFalpE-",
    "outputId": "7a63862d-3bbd-4ab3-b5e0-fb00235a2c24"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Importation des données\n",
    "\n",
    "file = \"SURF_data.xlsx\"\n",
    "data = pd.read_excel(<COMPLETER ICI> , decimal = ',')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6TWCFHcMzdLJ"
   },
   "source": [
    "\n",
    "<font color=\"#0066CC\"> 3. Pre-requis : les étapes </font>  \n",
    "Le Jeu de données brut comprend 10 variables. Notre objectif est d'évaluer la méthode des kppv pour l'estimation de la variable *chauff*. La variable *refroid* ne nous interessa pas et sera eliminée. \n",
    "Nous avons donc   \n",
    "* un data.frame X (Predicteur) composé des variables prédictives suivantes :  \n",
    "  - compacité\n",
    "  - Surface\n",
    "  - mur\n",
    "  - toit\n",
    "  - hauteur\n",
    "  - orientation\n",
    "  - vitrage\n",
    "  - or_vitre\n",
    "* un dataframe Y composé uniquement de la variable *chauff*  \n",
    "\n",
    "<br>\n",
    "\n",
    " \n",
    "3.1. Nous verifions dans un premier temps l'absence / présence de données manquantes   \n",
    "\n",
    "3.2  Certaines variables, bien que numériques, ne sont pas formatées correctement. En effet, les variables orientation et or_vit se référent à un orientation de type ; nord, sud, est, ouest,.... Il convient donc de les transformer. Deux étapes sont necessaires : (i) la labellisation puis(ii) un One Hot encoding\n",
    "\n",
    "3.3 La méthode des KPPV est fondée sur la calcul des distances entre les différents individus (lignes du prédicteur). Il est donc important de standardiser les données de type float64\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "RqBAdGs54MU6",
    "outputId": "769aca5f-f6fb-48fe-9d19-d40151078268"
   },
   "outputs": [],
   "source": [
    "#-> on vérifie la présence / absence de données manquantes\n",
    "data.isna().sum()\n",
    "#-> on élimine la variable refroid\n",
    "data.drop('refroid', axis = 1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous devez donc\n",
    "\n",
    "1. marquer les variables catéorielles (méthode `.astype`)\n",
    "2. sélectionner les variables catégorielles (méthode `.select_dtypes(include = ...)`)\n",
    "3. utiliser la librairie `OneHotEncoder` pour transformer les variables\n",
    "4. recréer un dataframe (la sortie de OHE est un array)\n",
    "5. sélectionner les variables quantitatives (méthode `.select_dtypes(exclude = ...)`)\n",
    "6. utiliser la librairie `StandardScaler` pour transformer les variables\n",
    "7. recréer un dataframe (la sortie de SC est un array)\n",
    "8. concaténer les deux dataframes\n",
    "\n",
    "Enfin, créer les matrices X (variables explicatives) et y (réponse)\n",
    "\n",
    "Les cellules suivantes vous guident dans la démarche standard qui permet d'utiliser les classes de *preprocessing*, en identifiant le stransformations que vous pourriez ensuite utiliser sur de nouveles données. Plus bas, on vous livre une version plus rapide mais moins précautionneuse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "RqBAdGs54MU6",
    "outputId": "769aca5f-f6fb-48fe-9d19-d40151078268"
   },
   "outputs": [],
   "source": [
    "#___________________________________________________________\n",
    "#  TRANSFORMATION DES VARIABLES : ONE HOT ENCODING\n",
    "#___________________________________________________________\n",
    "# 1. tranformation en variables catégorielle des deux variables\n",
    "data[['orientation','or_vitre']] = data[['orientation','or_vitre']].astype('category')\n",
    "# 2. One hot encoding\n",
    "#---------------------------------------------------\n",
    "# 2.1. On selectionne les variables catégorielles\n",
    "df_cat   = data.select_dtypes(include = <COMPLETER ICI>)\n",
    "name_cat = df_cat.columns\n",
    "#---------------------------------------------------\n",
    "#2.2 Appel et utilisation de la librairie pour l'encodage\n",
    "OH     = OneHotEncoder(handle_unknown='error',sparse=False)\n",
    "fit_OH = OH.fit(<COMPLETER ICI>)\n",
    "fit_data_OH    = fit_OH.transform(<COMPLETER ICI>)\n",
    "column_name_OH = fit_OH.get_feature_names(<COMPLETER ICI>)\n",
    "#---------------------------------------------------\n",
    "#2.3 On recrée un dataframe contenant les variables OneHot\n",
    "dfw_OH = pd.DataFrame(fit_data_OH,columns = column_name_OH)\n",
    "dfw_OH.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "RqBAdGs54MU6",
    "outputId": "769aca5f-f6fb-48fe-9d19-d40151078268"
   },
   "outputs": [],
   "source": [
    "#___________________________________________________________\n",
    "#  STANDARDISATION\n",
    "#___________________________________________________________\n",
    "# 1. sélection des variables numériques \n",
    "dfw_num   = data.select_dtypes(exclude = <COMPLETER ICI>)\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# 2. Centrage et réduction  \n",
    "SC       =  StandardScaler()\n",
    "fit_SC   =  SC.fit_transform(<COMPLETER ICI>)\n",
    "dfw_SC   =  pd.DataFrame(fit_SC, columns = dfw_num.columns)\n",
    "dfw_SC.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "RqBAdGs54MU6",
    "outputId": "769aca5f-f6fb-48fe-9d19-d40151078268"
   },
   "outputs": [],
   "source": [
    "#____________________________________________________________\n",
    "# DATAFRAME\n",
    "#---------------------------------------------------------\n",
    "# Dataframe contenant les variables standardisées / One Hot encodées\n",
    "#  On crée différents dataframe\n",
    "#---------------------------------------------------------\n",
    "# 1. Dataframe contenant Toutes les variables\n",
    "dfw_All = pd.concat(<COMPLETER ICI>, axis = <COMPLETER ICI>)\n",
    "dfw_All\n",
    "\n",
    "#---------------------------------------------------------\n",
    "# 2. Le dataframe contenant les variables prédictives (Predicteurs)\n",
    "X_num = dfw_All.drop('chauff', axis = 1)\n",
    "\n",
    "#---------------------------------------------------------\n",
    "# 2. Le dataframe contenant la variables à prédire (en régression)\n",
    "Y_num = dfw_All['chauff']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Une version rapide alternative..**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "var_quanti = ['compacité', 'Surface', 'mur', 'toit', 'hauteur', 'vitrage', 'chauff']\n",
    "data[var_quanti] = StandardScaler().fit_transform(data[var_quanti])\n",
    "#\n",
    "var_quali = ['orientation','or_vitre']\n",
    "data_quali_encoded = pd.get_dummies(data[var_quali])\n",
    "# \n",
    "df = pd.concat([data[var_quanti], data_quali_encoded], axis = 1)\n",
    "#\n",
    "X_num = df.drop('chauff', axis=1)\n",
    "Y_num = df['chauff']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yeJklpxbG_om"
   },
   "source": [
    "<font color=\"#0066CC\"> **4. KPPV en régression** </font>     \n",
    "<font color=\"#0066CC\"> 4.1 Régression avec  k fixe  </font>\n",
    "* Estimation des valeurs  \n",
    "Dans le cadre de la régression, l'objectif est de trouver le nombre de plus proche voisins (k) qui permet de \"s'approcher\" au mieux des valeurs observées dela variable *chauff*.   \n",
    "Comme nous l'avons vu dans le cours, Deux étapes sont nécessaires :  \n",
    "  * La phase d'entrainement ou l'on effectue le paramètrage (on fixe le k) sur un échantillon du jeu de données (70%) \n",
    "  * Puis la phase de validation (30%) où l'on évalue si le k fixé en entrainement estime correctement les valeurs observées (annotées) sur un autre échantillon du jeux de données (cf. shéma 1)  \n",
    "  * par défaut, nous fixons le nombre de k plus proches voisins = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "cbYrNEc1nr5j",
    "outputId": "daf6c386-03b2-4856-c187-d025b76ac038"
   },
   "outputs": [],
   "source": [
    "#_______________________________________________________________________________\n",
    "# PARTITION DU JEUX DE DONNEES (70% TRAIN - 30% VALIDATION)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(<COMPLETER ICI>, test_size= 0.30)\n",
    "\n",
    "#______________________________________________________________________________\n",
    "# KNN EN REGRESSION\n",
    "#-> on récupére le nombre de valeurs en test \n",
    "n_test = len(Y_test)\n",
    "KNN_Reg = KNeighborsRegressor(<COMPLETER ICI>)\n",
    "KNN_Reg.fit(<COMPLETER ICI>)\n",
    "Y_pred = KNN_Reg.predict(<COMPLETER ICI>)\n",
    "#_____________________________________________________________________________\n",
    "# On récupère les valeurs prédites\n",
    "#Y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gh4XlP_apje7"
   },
   "source": [
    "* Qualité de l'estimation \n",
    " La qualité  de l'estimation correspond à la moyenne de la somme des carrés des écarts entre les valeurs observées et les valeurs prédites (appelée erreur quadratique moyenne ou MSE en anglais) . Plus cette valeur est faible, meilleure sera la qualité de l'ajustement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "w9BQs4-trAfU",
    "outputId": "a18c0475-9ead-4484-c590-ac42d6aca3aa"
   },
   "outputs": [],
   "source": [
    "MSE = <COMPLETER ICI>\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CiAlVmEqrb_s"
   },
   "source": [
    "Visualisons la relation à l'aide d'un scatter plot entre les valeurs observée et prédites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame({'obs' : Y_test, 'pred': Y_pred})\n",
    "_ = sns.scatterplot(<COMPLETER ICI>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ym7b4pZevc9T"
   },
   "source": [
    "<font color=\"#0066CC\"> 4.2 Régression avec différentes valeurs de k </font>\n",
    "* Jusqu'à présent, nous avons fixé le nombre de plus proches voisins (=20) et nous obtenons une valeur de MSE qui reflète une certaine qualité de l'ajustement. La question que l'on peut se poser est alors la suivante :  Peut on améliorer la qualité de l'ajustement en modifiant le nombre de k ?\n",
    "\n",
    "* Pour y répondre, nous allons incrémenter le nombre de k et calculer, pour chaque incrément de k, l'erreur Quadratique moyenne. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bSPVd_1Z2Z2B"
   },
   "outputs": [],
   "source": [
    "kmax = 80\n",
    "#---> On stocke dans un array les erreurs quadratiques moyennes\n",
    "error_Reg =  np.zeros(kmax)\n",
    "#--> On fait varier les valeurs de k = 1 à kmax par pas de 1\n",
    "kppv = np.arange(1,kmax+1,1)\n",
    "#--> boucle \n",
    "for k in kppv:\n",
    "    <COMPLETER ICI>\n",
    "    Y_pred = <COMPLETER ICI>\n",
    "    #--> calcul MSE\n",
    "    MSE = <COMPLETER ICI>\n",
    "    #--> et stockage dans la liste\n",
    "    error_Reg[k-1] = MSE\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uW9PkEt33RC9"
   },
   "source": [
    "* Nous construisons le graphique MSE = f(k) et nous calculons le k optimal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "colab_type": "code",
    "id": "OQvecPi13nlg",
    "outputId": "bd2a7fb0-4f81-4688-c469-a561f9610585"
   },
   "outputs": [],
   "source": [
    "df_result_Reg = pd.DataFrame({ \n",
    "                          'k'   : kppv,\n",
    "                          'MSE' : error_Reg\n",
    "                        })\n",
    "\n",
    "k_opt = df_result_Reg['MSE'].values.argmin(0) + 1\n",
    "\n",
    "_ = df_result_Reg.plot(x='k', y='MSE', style='.-')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YTws9_Dv-RMs"
   },
   "source": [
    "* Nous comparons les valeurs observées (en x)  par rapport aux valeurs prédites pour k = 15 et pour le k optimal (en y). En théorie, si les prédictions correspondent \"exactement\" aux observations, on observe une droite. Comme ce n'est jamais le cas, plus les points se 'rapprocheront' d'une droite meilleure sera la prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s0FrHC9X_aa3"
   },
   "outputs": [],
   "source": [
    "\n",
    "#-> On calcule les valeurs pour la k optimal\n",
    "KNN_Reg = <COMPLETER ICI>\n",
    "KNN_Reg.fit(<COMPLETER ICI>)\n",
    "Y_pred_opt = KNN_Reg.<COMPLETER ICI>\n",
    "\n",
    "#--> On ajoute au dataFrame la variable pred_opt = résultats obtenus avec le k optimal\n",
    "df_result['pred_opt'] = Y_pred_opt\n",
    "\n",
    "_ = sns.scatterplot(x='obs', y='pred', data=df_result, label='k=20')\n",
    "_ = sns.scatterplot(x='obs', y='pred_opt', data=df_result, label='k=kopt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_result.sort_values(by='obs').plot(x='obs', y='pred', style='.-')\n",
    "df_result.sort_values(by='obs').plot(x='obs', y='pred_opt', style='.-', ax=ax)\n",
    "_ = ax.plot([-1.5, 2],[-1.5, 2], label='optimal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9bs3Y3INGi_6"
   },
   "source": [
    "* Comme on peut l'observer, il y a moins de dispersion des points lorsque nous utilisons le k_optimal (en marron sur le graphique)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TP_KNN_V1.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4rc1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "latex_bib.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "ctrl-e"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "nteract": {
   "version": "0.15.0"
  },
  "toc": {
   "base_numbering": "1",
   "lock_sidebar": true,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
